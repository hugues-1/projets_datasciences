{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "530cc79d-7655-4802-a839-52d871672f83",
   "metadata": {
    "id": "530cc79d-7655-4802-a839-52d871672f83",
    "tags": []
   },
   "source": [
    "# Recherche meilleurs algos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0037aef4-0776-475b-96ed-d689d758f4b7",
   "metadata": {},
   "source": [
    "## import librairies et Pré-traitements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f2e5131",
   "metadata": {
    "executionInfo": {
     "elapsed": 4290,
     "status": "ok",
     "timestamp": 1679249429952,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "9f2e5131"
   },
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix,accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "import imblearn as imb\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer\n",
    "from imblearn import FunctionSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe044698",
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1679244107103,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "fe044698"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a24b06ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25041,
     "status": "ok",
     "timestamp": 1679249455217,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "a24b06ad",
    "outputId": "1f90fb35-f123-461c-9067-39f8c4880768"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    base=pd.read_csv(\"/content/drive/MyDrive/Notebooks/P7/basep7.csv\")\n",
    "        \n",
    "except ModuleNotFoundError :\n",
    "    \n",
    "    base = pd.read_csv(\"basep7.csv\")\n",
    "    \n",
    "base = base.drop( columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a90ebe0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 796,
     "status": "ok",
     "timestamp": 1679249456002,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "9a90ebe0",
    "outputId": "903d926c-e191-4a79-99ed-bb42527b36ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 122)\n",
      "(307511, 262)\n"
     ]
    }
   ],
   "source": [
    "# one_hot_encoder classique pour les non numériques\n",
    "def one_hot_encoder(base, nan_as_category = True):\n",
    "    original_columns = list(base.columns)\n",
    "    categorical_columns = [col for col in base.columns if base[col].dtype == 'object']\n",
    "    base2 = pd.get_dummies(base, columns= categorical_columns, dummy_na= True)\n",
    "    new_columns = [c for c in base.columns if c not in original_columns]\n",
    "    return base2\n",
    "print (base.shape)\n",
    "base2 =one_hot_encoder(base)\n",
    "print (base2.shape)\n",
    "base = base2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b1f4fe-9a96-4d9e-8ed7-fcc2ac13becf",
   "metadata": {
    "executionInfo": {
     "elapsed": 1255,
     "status": "ok",
     "timestamp": 1679249457253,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "95b1f4fe-9a96-4d9e-8ed7-fcc2ac13becf"
   },
   "outputs": [],
   "source": [
    "# Remplacer les valeurs manquantes par la moyenne de la colonne\n",
    "base = base.fillna(base.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aadae66-a87c-4bc0-b4c5-5bc4001ea36f",
   "metadata": {
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1679249457502,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "7aadae66-a87c-4bc0-b4c5-5bc4001ea36f"
   },
   "outputs": [],
   "source": [
    "# Séparer les variables explicatives (X) et la variable cible (y)\n",
    "X = base.drop(\"TARGET\", axis=1)\n",
    "y = base[\"TARGET\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa8e359e-2e7a-4840-9a04-1a8cb2186357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 261)\n"
     ]
    }
   ],
   "source": [
    "# scaler \n",
    "col_names=X.select_dtypes(include='number').columns.tolist()\n",
    "features = X[col_names]\n",
    "scaler = StandardScaler().fit(features.values)\n",
    "features_scale = scaler.transform(features.values)\n",
    "X[col_names] = features_scale\n",
    "print (X.shape) \n",
    "del features\n",
    "del features_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e741f79e",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1679249457717,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "e741f79e"
   },
   "outputs": [],
   "source": [
    "# Améliore l'affichage des DataFrame de résultats. \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736b6bc1-d2c5-422d-91fc-47c5a36f2f5d",
   "metadata": {
    "id": "736b6bc1-d2c5-422d-91fc-47c5a36f2f5d"
   },
   "source": [
    "# fonction comparer algos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8843762e",
   "metadata": {
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1679249461923,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "8843762e"
   },
   "outputs": [],
   "source": [
    "def comp_algos(X,y,algos,params,cvi,scorer,sampling) : \n",
    "\n",
    "    \n",
    "    roc_aucs = []\n",
    "    confusions = []\n",
    "    Report_df = pd.DataFrame(columns=['Algorithme', 'score nom ','score']) \n",
    "    Append = []\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) \n",
    "    del X\n",
    "    del y\n",
    "    \n",
    "    # Apply oversampling\n",
    "    #ros = RandomOverSampler(random_state=42)\n",
    "    #X_resampled, y_resampled = sampling.fit_resample(X_train,y_train)\n",
    "    \n",
    "    for i in range(len(algos)): \n",
    "        \n",
    "        #faire boucle sur le sampling \n",
    "        for s in range(len(sampling)): \n",
    "            \n",
    "            # Apply sampling\n",
    "            \n",
    "            debut = time.time()\n",
    "            X_resampled, y_resampled = sampling[s].fit_resample(X_train,y_train)\n",
    "\n",
    "# Créer un objet GridSearchCV qui va comparer les performances des algorithmes sur les données en utilisant le score roc_auc comme critère d'évaluation \n",
    "            print (algos[i], params[i] )\n",
    "    \n",
    "          \n",
    "           \n",
    "            grid = GridSearchCV(estimator=algos[i], param_grid=params[i], scoring=scorer, cv=cvi, refit= True )\n",
    "          \n",
    "            grid.fit(X_resampled,y_resampled)\n",
    "            del X_resampled\n",
    "            del y_resampled\n",
    "            \n",
    "# Afficher le meilleur score et le meilleur algorithme trouvé par GridSearchCV \n",
    "            print(\"Meilleur score:\", grid.best_score_)\n",
    "            print(\"Meilleur algorithme:\", grid.best_estimator_)\n",
    "            #print ( \"cv results ;\", grid.cv_results_ ) \n",
    "            print ( \"best_params_\",grid.best_params_)\n",
    "            print (\"best_index_\",grid.best_index_)\n",
    "            print (\"scorer_\",grid.scorer_)\n",
    "            print (\"n_splits_\",grid.n_splits_)\n",
    "            print (\"sampling method\",sampling[s])\n",
    "    \n",
    "            cv_result= pd.DataFrame(grid.cv_results_)\n",
    "            display ( cv_result )\n",
    "\n",
    "# Prédire les classes pour chaque algorithme \n",
    "            pred_y_train = grid.predict(X_train)\n",
    "            score = accuracy_score(y_train,pred_y_train)\n",
    "            print ('accuracy train',score)\n",
    "          \n",
    "            roc_auc_train = roc_auc_score(y_train, pred_y_train)\n",
    "            #print ( 'roc_auc_train',roc_auc_train)\n",
    "            print(f'roc_auc_train: {roc_auc_train:.1%}')\n",
    "\n",
    "            pred_y_train_proba=grid.predict_proba(X_train)[:,1]\n",
    "            roc_auc_discret_train = roc_auc_score(y_train, pred_y_train_proba)\n",
    "            print( \"Roc auc train predict proba\",roc_auc_discret_train)\n",
    "        \n",
    "            pred_y_test = grid.predict(X_test)\n",
    "            score = accuracy_score(y_test,pred_y_test)\n",
    "            print ('accuracy test',score)\n",
    "          \n",
    "            roc_auc_test = roc_auc_score(y_test, pred_y_test)\n",
    "            print ( 'roc_auc_ test ',roc_auc_test)\n",
    "\n",
    "            pred_y_test_proba=grid.predict_proba(X_test)[:,1]\n",
    "            roc_auc_discret_test= roc_auc_score(y_test, pred_y_test_proba)\n",
    "            print( \"Roc auc score test predict proba\",roc_auc_discret_test)\n",
    "\n",
    "# Calculer la matrice de confusion pour chaque algorithme\n",
    "\n",
    "            matrice_confusion = confusion_matrix(y_true=y_train,y_pred=pred_y_train)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_true=y_train,y_pred=pred_y_train, normalize='all').ravel()\n",
    "\n",
    "# Change figure size and increase dpi for better resolution\n",
    "            plt.figure(figsize=(2,1), dpi=100)\n",
    "# Scale up the size of all text\n",
    "            sns.set(font_scale = 1)\n",
    "\n",
    "# Plot Confusion Matrix using Seaborn heatmap()\n",
    "# Parameters:\n",
    "# first param - confusion matrix in array format   \n",
    "# annot = True: show the numbers in each heatmap cell\n",
    "# fmt = 'd': show numbers as integers. \n",
    "            ax = sns.heatmap(matrice_confusion, annot=True, fmt='d', )\n",
    "\n",
    "# set x-axis label and ticks. \n",
    "            ax.set_xlabel(\"Prédiction \", fontsize=14, labelpad=20)\n",
    "            ax.xaxis.set_ticklabels(['Accepté', 'Refus'])\n",
    "\n",
    "# set y-axis label and ticks\n",
    "            ax.set_ylabel(\"réel \", fontsize=14, labelpad=20)\n",
    "            ax.yaxis.set_ticklabels(['Accepté', 'Refus'])\n",
    "\n",
    "# set plot title\n",
    "            titre = str(algos[i])\n",
    "            ax.set_title(titre, fontsize=14, pad=20)\n",
    "            plt.show()    \n",
    "     \n",
    "    \n",
    "#graphique\n",
    "\n",
    "            roc_auc_courbe = roc_auc_score(y_train, pred_y_train_proba)\n",
    "            print ('roc auc courbe',roc_auc_courbe)\n",
    "            fpr,tpr,_= roc_curve(y_train,pred_y_train_proba)\n",
    "    \n",
    "            plt.plot(fpr,tpr,label ='score (auc roc = %0.2f)' % roc_auc_courbe)\n",
    "            plt.plot([0,1],[0,1],'k--',label =\"random\")\n",
    "            plt.xlabel('Taux faux positifs')\n",
    "            plt.ylabel('Taux vrais positifs')\n",
    "            plt.title('ROC curve '+titre)\n",
    "            plt.legend(loc = 'lower right')\n",
    "            plt.show()\n",
    "            \n",
    "           \n",
    "            \n",
    "            # Créer un dataframe pandas qui contient les résultats de chaque algorithme\n",
    "            print(' score ', scorer,':' ,grid.best_score_)\n",
    "            duration = (time.time() - debut )/60\n",
    "            print (duration ,'minutes')\n",
    "            Append = pd.DataFrame([[ algos[i],grid.best_params_,scorer ,grid.best_score_,sampling[s],roc_auc_train,roc_auc_discret_train\n",
    "                                    ,roc_auc_test,roc_auc_discret_test,tn,fp,fn,tp,duration]]\n",
    "                                  ,columns=['Algorithme','Meilleur param', 'score nom ','best score','sampling','roc_auc_train'\n",
    "                                            ,'Roc_auc_train_discret','roc_auc_test','roc_auc_discret_test','TN','FP','FN','TP','minutes'])\n",
    "            Report_df = pd.concat([Report_df, Append]) \n",
    "            \n",
    "    return Report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xQ67woXm0I89",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1679247800747,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "xQ67woXm0I89"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b24a0a-15bd-497b-9f42-ee5518e27300",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "executionInfo": {
     "elapsed": 1009,
     "status": "error",
     "timestamp": 1679249315242,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "34b24a0a-15bd-497b-9f42-ee5518e27300",
    "outputId": "fb8d9470-6e66-4311-cede-9fa25e67e24f"
   },
   "outputs": [],
   "source": [
    "algos = [ LogisticRegression(random_state=22),DecisionTreeClassifier(random_state=22), RandomForestClassifier(random_state=22), \n",
    "         XGBClassifier(random_state=22), GaussianNB(),DummyClassifier()]\n",
    "\n",
    "# Définir une grille de paramètres à optimiser pour chaque algorithme\n",
    "params = [\n",
    "    \n",
    "    {\"C\": [0.01, 0.1, 1, 10], \"penalty\": [\"l1\", \"l2\", \"elasticnet\", 'none']}, # pour LogisticRegression \n",
    "    {\"max_depth\": [3, 5, 7], \"min_samples_leaf\": [5, 10, 15]}, # pour DecisionTreeClassifier\n",
    "    {\"n_estimators\": [100, 200], \"max_depth\": [3, 5]}, # pour RandomForestClassifier \n",
    "    {\"n_estimators\": [100, 200], \"learning_rate\": [0.01, 0.1]}, # pour XGBClassifier \n",
    "    {} ,# pas de paramètres à optimiser pour GaussianNB \n",
    "    {\"strategy\": [\"most_frequent\",\"prior\",\"stratified\",\"uniform\"]}, # pour DummyClassifier\n",
    "] \n",
    "\n",
    "\n",
    "cvi =2\n",
    "scorer = \"roc_auc\" \n",
    "def nosamplerfunc(X, y):\n",
    "    return X[:], y[:]\n",
    "nosampler = FunctionSampler(func=nosamplerfunc)\n",
    "\n",
    "\n",
    "sampling = [nosampler, RandomOverSampler(random_state=22),RandomUnderSampler(random_state=22),SMOTETomek(random_state=22)]\n",
    "\n",
    "\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "result_auc= comp_algos(X,y,algos,params,cvi,scorer,sampling)\n",
    "\n",
    "result_auc\n",
    "result_auc.to_excel(\"resultat_auc_200323.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "AFVTJ1fiEs_z",
   "metadata": {
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1679249565403,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "AFVTJ1fiEs_z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_auc.to_excel(\"resultat_auc_200323.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "TF6lG89j0Laa",
   "metadata": {
    "id": "TF6lG89j0Laa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_auc.to_csv(\"resultat_auc_200323.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87283b0-5da7-4b58-af28-890cbc154bc4",
   "metadata": {
    "id": "b87283b0-5da7-4b58-af28-890cbc154bc4"
   },
   "source": [
    "# optimisation scorer métier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba621a39-bfde-46c3-ac51-59d1ff98680c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ba621a39-bfde-46c3-ac51-59d1ff98680c",
    "outputId": "6f32f5a3-34ff-4ac6-a524-c289172ceed7"
   },
   "outputs": [],
   "source": [
    " algos = [ LogisticRegression(random_state=22),DecisionTreeClassifier(random_state=22), RandomForestClassifier(random_state=22), \n",
    "         XGBClassifier(random_state=22), GaussianNB(),DummyClassifier()]\n",
    "\n",
    "# Définir une grille de paramètres à optimiser pour chaque algorithme\n",
    "params = [\n",
    "    \n",
    "    {\"C\": [0.01, 0.1, 1, 10], \"penalty\": [\"l1\", \"l2\", \"elasticnet\", None]}, # pour LogisticRegression ‘l1’, ‘l2’, ‘elasticnet’, None\n",
    "    {\"max_depth\": [3, 5, 7], \"min_samples_leaf\": [5, 10, 15]}, # pour DecisionTreeClassifier\n",
    "    {\"n_estimators\": [100, 200], \"max_depth\": [3, 5]}, # pour RandomForestClassifier \n",
    "    {\"n_estimators\": [100, 200], \"learning_rate\": [0.01, 0.1]}, # pour XGBClassifier \n",
    "    {} ,# pas de paramètres à optimiser pour GaussianNB \n",
    "    {\"strategy\": [\"most_frequent\",\"prior\",\"stratified\",\"uniform\"]}, # pour DummyClassifier\n",
    "]\n",
    "\n",
    "cvi =3\n",
    "\n",
    "\"\"\"algos = [ DecisionTreeClassifier(random_state=22)]\n",
    "params = [ {\"max_depth\": [3], \"min_samples_leaf\": [5]}] # pour DecisionTreeClassifier\"\"\"\n",
    "\n",
    "def custom_score_func(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    score = tp + tn - fp -( 10 * fn)\n",
    "    #score 2 = tp + (10 * tn )- fp -(10 * fn)\n",
    "    return score\n",
    "\n",
    "\n",
    "# Création du scorer personnalisé\n",
    "score_metier= make_scorer(custom_score_func)\n",
    "\n",
    "scorer = score_metier\n",
    "\n",
    "def nosamplerfunc(X, y):\n",
    "    return X[:], y[:]\n",
    "nosampler = FunctionSampler(func=nosamplerfunc)\n",
    "\n",
    "sampling = [nosampler, RandomOverSampler(random_state=22),RandomUnderSampler(random_state=22),SMOTETomek(random_state=22)]\n",
    "\n",
    "\n",
    "\n",
    "result_metier= comp_algos(X,y,algos,params,cvi,scorer,sampling)\n",
    "result_metier\n",
    "\n",
    "result_metier.to_excel(\"resultat_metier_200323.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaf2478-e578-429c-be9d-34cd2029f146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c788cf4-1cbe-4e49-bf16-b4c37709011d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "executionInfo": {
     "elapsed": 558,
     "status": "error",
     "timestamp": 1679263668089,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "4c788cf4-1cbe-4e49-bf16-b4c37709011d",
    "outputId": "e74b3709-5e22-46d9-d5dc-28039d28c3e5"
   },
   "outputs": [],
   "source": [
    "#formatted_time = time.strftime(\"%Y-%m-%d-%H:%M:%S\", time.localtime(time.time()))\n",
    "#\"nom_excel='result_metier_'+ formatted_time +'.xlsx'\n",
    "result_metier.to_excel('score_metier_20323.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c718c341-9428-46a9-b104-ceb0275c2f6a",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1679247797304,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "c718c341-9428-46a9-b104-ceb0275c2f6a"
   },
   "outputs": [],
   "source": [
    "result_metier.to_csv('score_metier_20323.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66672f1-cffd-418e-818b-fb4cdd4cb02d",
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "aborted",
     "timestamp": 1679247797319,
     "user": {
      "displayName": "Hugues Hansen",
      "userId": "06507793026638313555"
     },
     "user_tz": -60
    },
    "id": "d66672f1-cffd-418e-818b-fb4cdd4cb02d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a229cb5",
   "metadata": {
    "id": "3a229cb5"
   },
   "source": [
    "Les courbes ROC permettent d’évaluer les performances d’un modèle de classification en fonction du seuil de décision choisi. Elles représentent le taux de vrais positifs (TPR) en fonction du taux de faux positifs (FPR) pour différents seuils. Plus la courbe est proche du coin supérieur gauche du graphique, plus le modèle est performant. L’aire sous la courbe (AUC) est une mesure synthétique qui résume la qualité d’un modèle: plus elle est proche de 1, mieux c’est.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
